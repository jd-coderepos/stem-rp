Aims of study To develop and validate a centile-based early warning score using manually-recorded data (mCEWS). To compare mCEWS performance with a centile-based early warning score derived from continuously-acquired data (from bedside monitors, cCEWS), and with other published early warning scores. Materials and methods We used an unsupervised approach to investigate the statistical properties of vital signs in an in-hospital patient population and construct an early-warning score from a “development” dataset. We evaluated scoring systems on a separate “validation” dataset. We assessed the ability of scores to discriminate patients at risk of cardiac arrest, unanticipated intensive care unit admission, or death, each within 24 h of a given vital-sign observation, using metrics including the area under the receiver-operating characteristic curve (AUC). Results The development dataset contained 301,644 vital sign observations from 12,153 admissions (median age (IQR): 63 (49–73); 49.2% females) March 2014–September 2015. The validation dataset contained 1,459,422 vital-sign observations from 53,395 admissions (median age (IQR): 68 (48–81), 51.4% females) October 2015–May 2017. The AUC (95% CI) for the mCEWS was 0.868 (0.864–0.872), comparable with the National EWS, 0.867 (0.863–0.871), and other recently proposed scores. The AUC for cCEWS was 0.808 (95% CI, 0.804–0.812). The improvement in performance in comparison to the continuous CEWS was mainly explained by respiratory rate threshold differences. Conclusions Performance of an EWS is highly dependent on the database from which itis derived. Our unsupervised statistical approach provides a straightforward, reproducible method to enable the rapid development of candidate EWS systems.