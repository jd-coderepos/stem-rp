This study aimed to improve the accuracy and robustness of a real-time assistive human machine interface system by classifying between the controlled movements related tongue-movement ear pressure (TMEP) signals and the interfering signals. The controlled movement TMEP signals were collected during left, right, up, down, flicking and pushing tongue motions. The TMEP signals were processed and classified using detection, segmentation, feature extraction and classification. The segmented signals were decomposed into the time-scale domain using a wavelet packet transform. The variance of the wavelet packet coefficients and its ratio between low-to-high scales were defined as features and the intended tongue movement commands and interfering signals were classified using both a Bayesian and support vector machine (SVM) classifiers for comparison. The average classification accuracy for discriminating between the controlled movements and the interfering signals achieved 97.8% (Bayesian) and 98.5% (SVM). The classifiers were robust remaining at a similar performance level when generalised interferences from all subjects were used. It was shown that the Bayesian classifier performed better than the SVM in a real-time environment. The approach of combining the Bayesian classifier and the wavelet packet transform provides a robust and efficient method for a real-time assistive human machine interface based on tongue-movement ear pressure signals.