Our ability to flexibly switch between different tasks is a key component of cognitive control. Non-human primate (NHP) studies (e.g., Freedman, Riesenhuber, Poggio, & Miller, 2001) have shown that prefrontal neurons are re-used across tasks, re-configuring their responses to code currently relevant information. In a similar vein, in the human brain, the “multiple demand” (MD) system is suggested to exert control by adjusting its responses, selectively processing information in line with our current goals (Duncan, 2010). However, whether the same or different resources (underlying neural populations) in the human brain are recruited to solve different tasks remains elusive. In the present study, we aimed to bridge the gap between the NHP and human literature by examining human functional imaging data at an intermediate level of resolution: quantifying the extent to which single voxels contributed to multiple neural codes. Participants alternated between two tasks requiring the selection of feature information from two distinct sets of objects. We examined whether neural codes for the relevant stimulus features in the two different tasks depended on the same or different voxels. In line with the electrophysiological literature, MD voxels were more likely to contribute to multiple neural codes than we predicted based on permutation tests. Comparatively, in the visual system the neural codes depended on distinct sets of voxels. Our data emphasise the flexibility of the MD regions to re-configure their responses and adaptively code relevant information across different tasks.