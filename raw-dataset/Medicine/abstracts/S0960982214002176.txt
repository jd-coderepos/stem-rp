The ability to self-localise and to navigate to remembered goals in complex and changeable environments is crucial to the survival of many mobile species. Electrophysiological investigations of the mammalian hippocampus and associated brain structures have identified several classes of neurons which represent information about an organismâ€™s position and orientation. These include place cells, grid cells, head direction cells, and boundary vector cells, as well as cells representing aspects of self-motion. Understanding how these neural representations are formed and updated from environmental sensory information and from information relating to self-motion is an important topic attracting considerable current interest. Here we review the computational mechanisms thought to underlie the formation of these different spatial representations, the interactions between them, and their use in guiding behaviour. These include some of the clearest examples of computational mechanisms of general interest to neuroscience, such as attractor dynamics, temporal coding and multi-modal integration. We also discuss the close relationships between computational modelling and experimental research which are driving progress in this area.