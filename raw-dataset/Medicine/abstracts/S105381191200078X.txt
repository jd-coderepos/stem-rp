We usually feel that we understand a familiar word “immediately”. However, even basic aspects of the time-line of word recognition are still controversial. Different domains of research have still not converged on a coherent account. An integration of multiple sources of information would lead to more strongly constrained theoretical models, and help finding optimal measures when monitoring specific aspects of word recognition impairments in patient groups. In our multimodal approach – combining fast behavioral measures, ERPs and EEG/MEG source estimation – we provide converging evidence for the latencies of earliest lexical and semantic information retrieval in visual word recognition. Participants performed lexical and semantic decisions (LD, SD) in a Go/NoGo paradigm. We introduced eye-blink latencies as a dependent variable, in order to measure behavioral responses that are faster and less variable than traditional button presses. We found that the earliest behavioral responses distinguishing stimulus categories can occur around 310ms. Ex-Gaussian analysis of behavioral responses did not reveal reliable differences between LD and SD. The earliest ERP differences between Go and NoGo conditions occurred around 160ms for both LD and SD. Distributed source analysis of combined EEG/MEG data estimated neuronal generators for the lexicality effect around 200ms in the left anterior middle temporal lobe. Thus, behavior and brain responses provide coherent evidence that the brain starts retrieving lexical and semantic information near-simultaneously within 200ms of word onset. Our results support models of word recognition that assume a continuous accumulation of task-related information from the stimulus, which might be described by Bayesian principles.