Driven by the interest of reasoning about probabilistic programming languages, we set out to study a notion of uniqueness of normal forms for them. To provide a tractable proof method for it, we define a property of distribution confluence which is shown to imply the desired uniqueness (even for infinite sequences of reduction) and further properties. We then carry over several criteria from the classical case, such as Newman's lemma, to simplify proving confluence in concrete languages. Using these criteria, we obtain simple proofs of confluence for λ 1 , an affine probabilistic λ-calculus, and for Q*, a quantum programming language for which a related property has already been proven in the literature.