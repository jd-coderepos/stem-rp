Humanoid robots are expected to be integrated into daily life. This requires the robots to perform human-like actions that are easily understandable by humans. Learning by imitation is an effective framework that enables the robots to generate the same motions that humans do. However, it is generally not useful for the robots to generate motions that are precisely the same as learned motions because the environment is likely to be different from the environment where the motions were learned. The humanoid robot should synthesize motions that are adaptive to the current environment by modifying learned motions. Previous research encoded captured human whole-body motions into hidden Markov models, which are hereafter referred to as motion primitives, and generated human-like motions based on the acquired motion primitives. The contact between the body and the environment also needs to be controlled, so that the humanoid robotâ€™s whole-body motion can be realized in its current environment. This paper proposes a novel approach to synthesizing kinematic data using the motion primitive and controlling the torques of all the joints in the humanoid robot to achieve the desired whole-body motions and contact forces. The experiments demonstrate the validity of the proposed approach to synthesizing and controlling whole-body motions by humanoid robots.