Legislation on vehicle emissions continues to become more stringent in an effort to minimise the impact of internal combustion engines on the environment. One area of significant concern in this respect is that of the cold-start; the thermal efficiency of the internal combustion engine is significantly lower at cold-start than when the vehicle reaches steady state temperatures owing to sub-optimal lubricant and component temperatures. The drive for thermal efficiency (of both the internal combustion engine and of the vehicle as a whole) has led to a variety of solutions being trialled to assess their merits and effects on other vehicle systems during this warm-up phase (and implemented where appropriate). The approaches have a common theme of attempting to reduce energy losses so that systems and components reach their intended operating temperature range as soon as possible after engine start. In the case of the engine, this is primarily focused on the lubricant system. Lubricant viscosity is highly sensitive to temperature and the increased viscosity at low temperatures results in higher frictional and pumping losses than would be observed at the target operating temperature. The approaches used to tackle the problem include the use of phase change materials (to reduce the cool-down rate during a period following engine running) [1,2] and the use of thermal barrier coatings in an attempt to insulate the cylinder bore and prevent heat loss (thus increasing the amount of energy utilised as brake work [3]). A range of system alterations have also been trialled including diversion systems on the lubricant circuit to reduce thermal losses. Presented here is a critical review of the research into vehicle thermal management during the cold-start phase which has been driven by a desire to improve both engine and overall vehicle engine efficiency. The review includes both system developments and material selection issues and the role the two fields have to play in tackling this critical issue.