Maximum sound pressure levels are commonly used for environmental noise and building acoustics measurements. This paper investigates the signal processing errors due to Fast or Slow time-weighting detectors when combined with octave band filters, one-third octave band filters or an A-weighting filter. For 6th order Butterworth CPB filters the inherent time delay caused by the phase response of filters is quantified using three different approaches to establish the following rules-of-thumb: (1) time-to-gradient/amplitude matching occurs when Bt ≈1, (2) time-to-peak matching occurs when Bt ≈2 and (3) time-to-settle matching occurs when Bt ≈4 for octave band filters, and when Bt ≈3 for one-third octave band filters. Four different commercially-available sound level meters are used to quantify the variation in measured maximum levels using tone bursts, half-sine pulses, ramped noise and recorded transients. Tone bursts indicate that Slow time-weighting is inappropriate for maximum level measurements due to the large bias error. The results also show that there is more variation between sound level meters when considering Fast time-weighted maximum levels in octave bands or one-third octave bands than with A-weighted levels. To reduce the variation between measurements with different sound level meters, it is proposed that limits could be prescribed on the phase response for CPB filters and A-weighting filters.