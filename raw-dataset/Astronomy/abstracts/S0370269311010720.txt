We examine a cosmological model with a dark energy density of the form ρ DE ( t ) = ρ X ( t ) + ρ Z ( t ) , where ρ X is the component that accelerates the Hubble expansion at late times and ρ Z ( t ) is an extra contribution proportional to H 2 ( t ) . This form of ρ Z ( t ) follows from the recent proposal that the contribution of zero-point fluctuations of quantum fields to the total energy density should be computed by subtracting the Minkowski-space result from that computed in the FRW space–time. We discuss theoretical arguments that support this subtraction. By definition, this eliminates the quartic divergence in the vacuum energy density responsible for the cosmological constant problem. We show that the remaining quadratic divergence can be reabsorbed into a redefinition of Newtonʼs constant only under the assumption that ∇ μ 〈 0 | T μ ν | 0 〉 = 0 , i.e. that the energy–momentum tensor of vacuum fluctuations is conserved in isolation. However in the presence of an ultra-light scalar field X with m X < H 0 , as typical of some dark energy models, the gravity effective action depends both on the gravitational field and on the X field. In this case general covariance only requires ∇ μ ( T μ ν X + 〈 0 | T μ ν | 0 〉 ) . If there is an exchange of energy between these two terms, there are potentially observable consequences. We construct an explicit model with an interaction between ρ X and ρ Z and we show that the total dark energy density ρ DE ( t ) = ρ X ( t ) + ρ Z ( t ) always remains a finite fraction of the critical density at any time, providing a specific model of early dark energy. We discuss the implication of this result for the coincidence problem and we estimate the model parameters by means of a full likelihood analysis using current CMB, SNe Ia and BAO data.